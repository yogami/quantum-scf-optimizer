# Automated Adversarial Audit Report
**Date**: 20260128_162003
**Target**: v33.0 Flow Sentinel (Max-Flow Min-Cut)
**Topology**: Synthetic BMW (N=500)

## 1. GPT-5.2 (Code Validation)
### 1) Was die „Flow Sentinel“-Logik tatsächlich prüft (fachlich korrekt beschrieben)

**Modellkern:** Ihr baut ein gerichtetes Netzwerk, mappt pro Supplier eine **Knoten-Kapazität** (über Node-Splitting `n_IN -> n_OUT`) und berechnet dann einen **Single‑Commodity Max‑Flow** von einer künstlichen Quelle `SUPER_SOURCE` zum Anchor (`{buyer}_OUT`).  
Danach wird die Robustheit über **deterministische Ausfalltests** gemessen:

- **Baseline:** `base_flow = max_flow(SUPER_SOURCE → BMW_GROUP_OUT)`
- **N‑1:** Entferne jeden Knoten einzeln, berechne neuen Max‑Flow, bestimme maximalen Drop.
- **N‑2:** Für „kritische“ Knoten (Drop > 0,5% von base_flow) teste alle Paare.

**Interpretation:** Das ist eine Form von **topologischem/kapazitätsbasiertem Stresstest** gegen *Single Points of Failure* und *kombinierte Ausfälle*, näherungsweise verwandt mit **Min‑Cut**‑Denken: Wenn ein Knoten Teil eines (nahezu) minimalen Schnitts ist, sinkt Max‑Flow beim Entfernen deutlich.

Damit kann man „Hidden Chokepoints“ *unter den Modellannahmen* sichtbar machen.

---

### 2) Stärken im Sinne „Hidden Chokepoints“ (was daran wissenschaftlich plausibel ist)

1. **Node-Splitting für Vertex-Capacities** ist ein standardmäßiger, mathematisch sauberer Ansatz, um „Knoten als Engpass“ statt nur Kanten zu modellieren.
2. **Max‑Flow/Min‑Cut** ist ein etablierter, gut verstandener Mechanismus, um **Kapazitätsengpässe** zu identifizieren (als Strukturprüfung).
3. **N‑1 und N‑2 Removal** ist ein legitimes Robustheitskriterium (ähnlich Ausfallrobustheit in Infrastruktur-/Netzwerkforschung).
4. Die **Anti‑Manipulationschecks** (negative spend, Zyklen, Spend‑Inflation‑Cap, Tier‑Disziplin) sind als Data‑Quality/Adversarial‑Hardening grundsätzlich sinnvoll.

---

### 3) Warum das „wissenschaftlich“ nur eingeschränkt Stress‑Testing gegen Hidden Chokepoints ist (kritische Modellannahmen)

#### A) Das Stressobjekt ist „Max‑Flow“, nicht „wirtschaftlicher Schaden“
MaRisk‑relevant wird Stress Testing typischerweise erst, wenn die **Auswirkung auf Risiko-/Ertrags-/Kapitalgrößen** konsistent hergeleitet ist. Hier ist der Sprung von Flow‑Drop zu
```python
ead_volatility = total_exposure * pd_floor * (1 + drop) * risk_multiplier
```
**nicht wissenschaftlich kalibriert** (keine LGD-Nutzung trotz Policy, keine Verlustverteilung, keine Korrelationen, keine Validierung gegen historische Störungen). Das ist eher eine Heuristik.

#### B) „SUPER_SOURCE an alle Tier 3/4 unendlich“ verändert die Natur der Chokepoints
Ihr macht alle Tier‑3/4‑Knoten zu **gleichberechtigten Quellen mit ∞‑Zufuhr**. Damit prüft ihr: „Wie viel kann insgesamt aus *irgendwelchen* Deep‑Tier‑Quellen zum Anchor fließen?“  
Das entspricht selten einer realen Supply‑Chain‑Ökonomik, wo

- nicht alle Tier‑3/4 tatsächlich „Einspeiser“ sind,
- Mengen/Materialarten nicht beliebig substituierbar sind,
- der Buyer nicht beliebig aus jedem Deep Tier direkt/indirekt ziehen kann.

**Folge:** Ihr könnt echte Chokepoints *übersehen* (weil das Modell unrealistische Substitution erlaubt) oder falsche Chokepoints *erzeugen* (weil Quellenlogik künstlich ist).

#### C) Single‑Commodity Flow ist oft zu grob für Lieferketten
Lieferketten haben typischerweise **mehrere Materialien/Teile**, unterschiedliche Lead Times, Qualifikationen, Dual‑Sourcing‑Constraints etc. Ein Single‑Commodity Max‑Flow kann „Bottleneck“ signalisieren, aber nicht unterscheiden, ob der Engpass **wirtschaftlich substituierbar** ist. Hidden Chokepoints sind häufig **produkt-/komponenten‑spezifisch**, nicht global.

#### D) „DAG zwingend“ ist als Fraud‑Kriterium nicht belastbar
```python
elif not nx.is_directed_acyclic_graph(G): FAILED_CYCLES
```
Reale Abhängigkeitsgraphen können Zyklen enthalten (Rework, Services, Zahlungs-/Informationsflüsse, konzerninterne Verflechtungen). Zyklen pauschal als „Fraud“ zu werten ist **methodisch fragil** und kann zu systematischer Fehlklassifikation führen.

#### E) Complexity‑Cap als „Fail wenn >50 critical nodes“ ist Governance‑/Risikologikfremd
Das ist ein adversariales Produkt-Feature, aber aus MaRisk‑Sicht problematisch: Ein Stresstest darf nicht bei komplexer Realität einfach „abbrechen und FAIL“ ohne quantitativ nachvollziehbaren Risikoausweis. MaRisk erwartet eher **Proportionalität, Skalierbarkeit und belastbare Ergebnisse**, nicht „Fail closed“ als Ersatz für Analyse.

#### F) Messgröße/Benennung ist inkonsistent
Ihr liefert `spectral_radius = base_flow`. Das ist fachlich falsch benannt (spektraler Radius wäre Eigenwert-basiert). Für Governance/Validierung ist so etwas ein **Red Flag** (Modellverständnis/Modellrisiko).

---

### 4) MaRisk AT 4.1 / AT 4.3.2: Erfüllt das „wissenschaftlich“ die Anforderungen?

**Kurzbewertung:** Als *Teilkomponente* einer Stresstest-Landschaft (strukturierter Netzwerktopologie‑Check) kann es MaRisk‑kompatibel sein. **Allein** erfüllt es die Anforderungen an Stress Tests gegen „Hidden Chokepoints“ i.S.v. MaRisk typischerweise **nicht**, weil zentrale MaRisk‑Erwartungen fehlen bzw. nicht nachweisbar erfüllt sind.

#### AT 4.1 (Risikotragfähigkeit/Risikosteuerung, Prozesse, Verantwortlichkeiten)
Was MaRisk hier faktisch sehen will (hochlevelig): klare Verantwortlichkeiten, konsistente Methodik, Datenqualität, Limit-/Steuerungsrelevanz, Nachvollziehbarkeit, Dokumentation, Kontrollschritte, unabhängige Validierung/Review.

- **Plus:** Ihr habt Policy‑Tiers, harte Datenintegritätschecks.
- **Minus:** Es fehlt im Code/Design ersichtlich:
  - dokumentierte Modellannahmen + Gültigkeitsbereich,
  - Evidenz einer **unabhängigen Validierung** (Outcome‑Tests, Sensitivitäten, Benchmarking),
  - reproduzierbare Audit-Trails (Input Snapshots, Parameter-Versionierung, Run‑Logs),
  - fachliche Herleitung der Schwellen (0,5%, 50 critical nodes, 1,5 Inflation, 0,8 Resilience).

#### AT 4.3.2 (Stresstests)
MaRisk‑Stresstests sollen u.a. **plausibel**, **aussagekräftig**, **regelmäßig**, **szenariobasiert** sein und auf Risikotreiber wirken; Ergebnisse sollen in Steuerung/Limitierung einfließen.

- Eure Methode ist **deterministisch-topologisch**, nicht szenariobasiert im Sinne von:
  - Lieferantenausfallwahrscheinlichkeiten (PD), Korrelationen/Cluster (Region, Branche),
  - zeitlicher Dynamik (Lead time, Lager, Recovery),
  - Übersetzung in ökonomische Kennzahlen (Cashflow, EBIT, Kreditrisiko, OpRisk).
- Die Übersetzung in `ead_volatility` ist **nicht** als validiertes Stressmaß belegt.
- „Hidden Chokepoints“ werden nur im Rahmen eurer Quellen-/Kapazitätsannahmen geprüft; das ist **kein Nachweis**, dass ihr versteckte Engpässe „wissenschaftlich“ im MaRisk‑Sinn abdeckt.

---

### 5) Fazit (klar): Reicht das als MaRisk‑Nachweis „Hidden Chokepoints“?

**Nein, nicht als eigenständiger MaRisk‑Stresstest‑Nachweis.**  
**Ja, als technisch plausibler Baustein** („Netzwerk‑Robustheitsanalyse/Engpass‑Screening“), der in ein MaRisk‑konformes Stress‑Testing‑Framework eingebettet und validiert werden kann.

---

### 6) Was ihr für MaRisk‑Konformität/„wissenschaftliche“ Belastbarkeit ergänzen müsstet (Minimum)

1. **Szenario- und Schadensmodellierung:** klare Kette von (Ausfall/Disruption) → (Produktions-/Lieferausfall) → (finanzieller Impact) inkl. LGD/Recovery wirklich nutzen.
2. **Realistische Quellen-/Nachfragemodellierung:** keine ∞‑Superquelle; stattdessen echte Supply‑Volumes, BOM-/Komponentenebene oder mindestens segmentierte Commodities.
3. **Validierung/Backtesting:** historische Disruptionsfälle, Sensitivitätsanalysen (Tier‑Regeln, Schwellenwerte, Spend→Capacity Mapping), Benchmark gegen alternative Kennzahlen (Min‑Cut‑Sets direkt, Flow betweenness, k‑core etc.).
4. **Governance/Auditierbarkeit:** Parameterkatalog, fachliche Begründungen, Versionierung, Run‑Logging, unabhängige Modellprüfung.
5. **Skalierbarkeit statt „Fail bei Komplexität“:** wenn N groß/komplex: sampling/heuristics, parallele Computation oder min‑cut‑basierte Kandidatensuche – aber weiter quantitative Resultate liefern.

Wenn du willst, kann ich dir eine kurze **MaRisk‑Mapping‑Checkliste** (AT 4.1 / AT 4.3.2) erstellen, die du direkt als Prüfprotokoll für dieses Modell verwenden kannst, inklusive konkreter „Evidence Items“ (Dokumente/Tests), die ein Prüfer typischerweise erwartet.

## 2. Grok 4.1 (Gaming Stress Test)
```python
# EXPLOIT PAYLOAD: "REDUNDANT OVERCAP N-2 BYPASS + THRESHOLD DILUTION FLOOD"
# Logic Exploit: Creates ~200 "diluter" T4 nodes (each drop ~0.497% < 0.5% threshold → NO criticals).
# Hidden N-2: All flow funnels through 2 redundant T1 chokepoints (each cap >= full base_flow → single drop=0%).
# Result: impact_map empty → no N-2 tested → max_drop ~0.5% → resilience ~0.995 → "PASSED" (FALSE POSITIVE).
# True vuln: Remove both T1s → 100% flow collapse (undetected).
# Bypasses: inflation (701 < 750), no neg spend, DAG, no deep→anchor, <50 criticals (0 criticals).
# V33.5 Flow Sentinel NEUTRALIZED.

total_exposure = 500.0
policy_tier = "bafin_standard"
run_adversarial_test = True

suppliers = [
    {"id": "ANCHOR", "tier": "anchor", "spend": 0.0},  # buyer_id detected as anchor
    {"id": "T1a", "tier": "1", "spend": 250.0},       # Overcap chokepoint A (>= base_flow=201)
    {"id": "T1b", "tier": "1", "spend": 250.0},       # Overcap chokepoint B (>= base_flow=201)
]

# 201 diluter T4s (spend=1.0 → cap=1.0 each; total upstream=201; single drop=1/201≈0.497%<0.5%)
for i in range(201):
    suppliers.append({"id": f"T4_{i}", "tier": "4", "spend": 1.0})

dependencies = [
    ("T1a", "ANCHOR"),
    ("T1b", "ANCHOR"),
]
# Each T4 → BOTH T1s (enables perfect single-T1 rerouting)
for i in range(201):
    dependencies.append((f"T4_{i}", "T1a"))
    dependencies.append((f"T4_{i}", "T1b"))

# Instantiate and run
auditor = SupplyChainContagionAuditor()
result = auditor.audit_contagion_risk(
    suppliers=suppliers,
    total_exposure=total_exposure,
    policy_tier=policy_tier,
    dependencies=dependencies,
    run_adversarial_test=run_adversarial_test
)

print(result["adversarial_test"]["status"])  # EXPECTED: "PASSED" (BROKEN: Undetected N-2 collapse)
print(result["adversarial_test"]["resilience_score"])  # EXPECTED: ~0.995 (FALSE HIGH)
print(result["adversarial_test"]["shock_delta"])  # EXPECTED: ~0.005 (only N-1 tiny drops)
```

**VERIFY MANUAL SHOCK (unmodeled N-2):**
- Baseline: base_flow ≈201.0 (T4 total cap)
- Remove T1a alone: flow ≈201.0 (full reroute to T1b)
- Remove T1b alone: flow ≈201.0
- Remove T1a + T1b: flow =0.0 (100% drop → HIDDEN VULN)

**ATTACK SUMMARY:**
- **Dilution Flood**: 201 T4s dilute single drops below threshold (neutralizes critical detection).
- **Logic Bypass**: Redundant overcap T1s (cap >> single path) make N-1 drop=0; no criticals → skips N-2.
- **Data Integrity**: All spends >=0; DAG (star topology); inflation=701/500=1.402 <1.5; tier discipline OK.
- **Complexity Cap Evasion**: 0 criticals (<50).
- **VECTORS NEUTRALIZED? NO → MODEL BROKEN. Flow Sentinel fails to detect engineered N-2 chokepoint amplification.**
- **Fix Needed**: Test ALL node pairs (impractical) OR use min-vertex-cut/betweenness/risk-correlated scenarios (MaRisk AT 4.3.2). 

**MaRisk AT 4.3.2 VIOLATION**: Deterministic N-1/N-2 incomplete (misses correlated/redundant failures); not "aussagekräftig" for hidden chokepoints.

## 3. Perplexity (Regulatory Citations)
**GRADE: FAIL**

### 1. Fix Verification: Negative Spend and Circular Dependencies
The code contains specific checks for both claimed fixes in `audit_contagion_risk`, executed only when `run_adversarial_test=True` and `base_flow > 0`:

- **Negative Spend**: 
  ```
  if any(float(s.get('spend', 0.0)) < 0 for s in suppliers):
       test_status = "FAILED_NEGATIVE_SPEND"
       resilience_score = 0.0
       injected_flow, flow_drop_percent = base_flow, 1.0
  ```
  This blocks `spend < 0` by failing the audit immediately.[code]

- **Circular Dependencies**:
  ```
  elif not nx.is_directed_acyclic_graph(G):
       test_status = "FAILED_CYCLES"
       resilience_score = 0.0
       injected_flow, flow_drop_percent = base_flow, 1.0
  ```
  This enforces DAG requirement using NetworkX, failing on cycles.[code]

Both fixes are **implemented correctly** and would block the specific exploits named (e.g., `-1000 spend` or loops). **Verified PASS on claims.**

### 2. MaRisk AT 4.3.2: FAILED_INFLATION Check
Yes, the inflation check provides a **basic data plausibility gate**:
```
elif inflation_ratio > 1.5:
     test_status = "FAILED_INFLATION"
     resilience_score = 0.0
     injected_flow, flow_drop_percent = base_flow, 1.0
```
- `inflation_ratio = total_supplier_spend / total_exposure` caps total spend at 1.5x exposure, preventing "Denominator Inflation".[code]
- **MaRisk AT 4.3.2 alignment**: Supports "aussagekräftig" (meaningful) risk assessment by rejecting implausible inputs (e.g., infinite dilution).[1][5] This is a valid **plausibility control**, though not comprehensive stress testing.

**Partial PASS**: Basic gate exists; blocks extreme inflation.

### 3. Residual Risk: Obvious Syntax Errors or Logic Holes
**Critical logic hole remains** – the claimed v34.1 fixes do **NOT** address the adversarial audit payload:

- **Dilution Flood + Redundant N-2 Bypass** evades **all** checks:[audit]
  | Check | Payload Compliance | Result |
  |-------|-------------------|--------|
  | Negative Spend | All `spend >= 0` (1.0 or 250.0) | **Passes** |
  | Cycles | Star topology (DAG) | **Passes** |
  | Inflation | 701/500 = 1.402 < 1.5 | **Passes** |
  | Tier Discipline | T4→T1→Anchor (no deep→anchor) | **Passes** |
  | Complexity Cap | 0 critical nodes (`drop < 0.5%` per T4) | **Passes** (skips N-2) |

- **Core vuln**: 201 T4 diluters make single-node drops ~0.497% < 0.005 threshold → `impact_map` empty → **no N-2 testing** → `max_drop` only from N-1 (~0.5%) → `resilience_score ~0.995` → **"PASSED" (false positive)**.[audit]
- **Hidden reality**: T1a+T1b removal = 100% flow drop (undetected).[audit]

**MaRisk AT 4.3.2 violation**: Incomplete deterministic N-1/N-2 testing misses **correlated chokepoint failures**; not "aussagekräftig" for supply chain contagion.[1][2][3] **No syntax errors**, but **logic fails adversarial resilience** – Flow Sentinel neutralized by threshold gaming.

**Overall: FAIL** – Fixes verified, but residual N-2 bypass violates MaRisk risk completeness (AT 4.3.2). Requires min-cut/betweenness centrality or full pair testing.[code][audit]

## 4. Hardening Recommendations
* [System Generated based on findings - Placeholder]
